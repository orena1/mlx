<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="A blog for machine learning experiments.">
    

    <!--Author-->
    
        <meta name="author" content="Pranav Rajpurkar">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Validating the CheXpert model on your own data in an hour"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="A blog for machine learning experiments." />
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="mlx"/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

        <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="rajpurkar>" />
    

    
        <link rel="icon" type="image/png" href="/mlx/img/favicon.png">
    

    <!-- Title -->
    
    <title>Validating the CheXpert model on your own data in an hour - mlx</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/mlx/bower_components/bootstrap/dist/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/mlx/css/style.css">

    <!-- Custom Fonts -->
    <link rel="stylesheet" href="/mlx/bower_components/components-font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/mlx/bower_components/lato-font/css/lato-font.min.css">

    <!-- Google Analytics -->
    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-106613516-1', 'auto');
        ga('send', 'pageview');

    </script>



</head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/mlx/">mlx</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/mlx/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/mlx/archives">
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="https://github.com/rajpurkar/mlx">
                            
                                <i class="fa fa-github fa-stack-2x"></i>
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('/mlx/img/bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-md-9">
                <div class="post-heading">
                    <h1>Validating the CheXpert model on your own data in an hour</h1>
                    
                    <h2 class="post-subheading">
                        A Walkthrough For External Validation of Chest X-Ray Interpretation
                    </h2>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                            By Pranav Rajpurkar, Jeremy Irvin, Matt Lungren on
                        
                        July 13th 2019
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Gallery -->
            
            <!-- Post Main Content -->
            <div class="col-md-9">
                <p>In this post, we provide a walkthrough of how you can run a chest x-ray interpretation model on your own data without writing any code, in just an hour!</p>
<h3 id="CXR-Interpretation-Our-Journey-and-Next-Frontier"><a href="#CXR-Interpretation-Our-Journey-and-Next-Frontier" class="headerlink" title="CXR Interpretation: Our Journey and Next Frontier"></a>CXR Interpretation: Our Journey and Next Frontier</h3><p>In the <a href="https://stanfordmlgroup.github.io">Stanford Machine Learning Group</a> and the <a href="http://aimi.stanford.edu">AIMI center</a>, chest x-ray interpretation, a <em>bread and butter</em> problem for radiologists with vital public health implications, has been one of our primary focus areas.</p>
<p>In late 2017, using the <a href="https://arxiv.org/abs/1705.02315">NIH’s Chest X-ray14 dataset</a> released by Xiaosong Wang et al., we built an algorithm (<a href="https://arxiv.org/abs/1711.05225">CheXNet</a>) to detect pneumonia and showed that its performance was comparable to radiologists; <a href="https://lukeoakdenrayner.wordpress.com/2018/01/24/chexnet-an-in-depth-review/">Luke Oakden-Rayner</a>, <a href="https://n2value.com/blog/chexnet-a-brief-evaluation/">Stephen Borstelmann</a> and others reviewed some of the strengths and weaknesses of our setup. In late 2018, we <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002686">published work</a> showing that an extension of CheXNet (<a href="https://stanfordmlgroup.github.io/projects/chexnext/">CheXNeXt</a>) could detect upto 10 pathologies at the level of 9 radiologists; at the same time, work by <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002683">John Zech at al.</a> showed that a reimplementation of CheXNet did generalized to another institution’s data. In early 2019, we built and released <a href="https://arxiv.org/abs/1901.07031">CheXpert</a>, a large dataset of chest x-rays and competition for chest x-ray interpretation (co-released with MIT’s release of <a href="https://arxiv.org/abs/1901.07042">MIMIC-CXR</a> by Alistair Johnson et al., and reported a similar finding of performing comparably to radiologists on some pathologies. Over the past few months, development of chest x-ray interpretation algorithms have been accelerating, with now over 32 models submitted to the <a href="https://stanfordmlgroup.github.io/competitions/chexpert/">CheXpert competition</a>.</p>
<p>Since we published our findings, there have been several groups attempting to reproduce our algorithms (<a href="https://github.com/zoogzog/chexnet">1</a>, <a href="https://github.com/brucechou1983/CheXNet-Keras">2</a>, <a href="https://github.com/arnoweng/CheXNet">3</a>, <a href="https://medium.com/@jrzech/reproducing-chexnet-with-pytorch-695ff9c3bf66">4</a>), and validate them on their own datasets. This is an encouraging signal – before chest x-ray interpretation algorithms can impact clinical care, it is important that they be validated on data from other institutions, countries, and patient populations. Validation provides valuable information about the generalizability of the model to different settings, and informs settings in which further development is required for safe and effective use of algorithms.</p>
<h3 id="Making-it-Easy-for-Everyone-to-Validate-Our-Models"><a href="#Making-it-Easy-for-Everyone-to-Validate-Our-Models" class="headerlink" title="Making it Easy for Everyone to Validate Our Models"></a>Making it Easy for Everyone to Validate Our Models</h3><p>We set ourselves the <strong>challenge of making it as easy as possible for everyone to use our chest x-ray algorithm for validation</strong> on external data. Getting an algorithm on a new dataset is traditionally a challenging and tedious task, usually requiring computer science expertise, and patience to work through a lot of installation setup. Computer science practitioners are well aware that even when the code is open-sourced, it takes a lot of trial and error to work through installation if the dependencies are not cross-platform, or worse, if they haven’t been specified. Deep learning practice can be even more challenging: local installation is hard because the models may not even fit in local memory. In the remainder of this post, we provide a walkthrough of how you can run a chest x-ray interpretation model on your own data without writing any code, in just an hour!</p>
<h2 id="Walkthrough-of-Validating-CheXpert-model-on-your-own-data"><a href="#Walkthrough-of-Validating-CheXpert-model-on-your-own-data" class="headerlink" title="Walkthrough of Validating CheXpert model on your own data"></a>Walkthrough of Validating CheXpert model on your own data</h2><p><em>For this walkthrough, you don’t need any coding experience. You also don’t need any data: we’ll provide you data example we use for this walkthrough. We had three friends go through this walkthrough; it took them 1.5 hours on average.</em></p>
<p><strong>If you don’t have a dataset right now, <a href="https://drive.google.com/drive/folders/1WVKMv9NWwxg69XZcTtjJgdl9IdKkEJ8T?usp=sharing">download the data we’ve generated</a>, and skip to the <a href="#Running-the-CheXpert-model-on-your-data">next section</a>.</strong></p>
<h3 id="How-to-Set-Up-Your-Data-Formatting-and-Organization"><a href="#How-to-Set-Up-Your-Data-Formatting-and-Organization" class="headerlink" title="How to Set Up Your Data: Formatting and Organization"></a>How to Set Up Your Data: Formatting and Organization</h3><p><em>If you’re coming in with your own data, this section will help you transform it to the right format.</em></p>
<p>In this section, we’re going to get your data into a format that the algorithm expects. There will be three things we’ll need: a folder containing x-ray images, a file containing a list of images to be passed into the algorithm, and a file containing information about the ground truth for each of the studies.</p>
<p>For the purposes of this walkthrough, we’ve compiled a dataset of google images of chest x-rays. We constructed this dataset of 96 images by googling for 5 pathologies (Cardiomegaly, Edema, Consolidation, Atelectasis, and Pleural Effusion) on Google Image search and also the Normal category. The first 16 image results judged to not have any annotations on them were chosen to be included. There was no verification of the ground truth performed; this is just a fun dataset that we can share for this tutorial.</p>
<p><br></p>
<h4 id="Image-Directory"><a href="#Image-Directory" class="headerlink" title="Image Directory"></a>Image Directory</h4><p>The first thing we’ll need is a folder containing all the images in the dataset. We’ll be organizing these images in a very specific format: we recommend that you follow the details closely.<br><em>If you’re using the example <a href="https://drive.google.com/drive/folders/1WVKMv9NWwxg69XZcTtjJgdl9IdKkEJ8T?usp=sharing">dataset provided</a>, all the data will already be in the right format, and you can skip to the <a href="#Running-the-CheXpert-model-on-your-data">next section</a>.</em></p>
<img src="/mlx/chexpert-validate/dataset_folder.png" alt="Example image directory" title="Example image directory"><span class="image-caption">Example image directory</span>
<p>The folder should be structured in the following way:</p>
<ol>
<li>The folder should be named ‘dataset’.</li>
<li>Inside ‘dataset’, there should be folders for every patient (example: patient001).</li>
<li>Insider every patient folder, there should be a study folder. Each study can have a different ground truth. (example: study1) <em>In our example, we only have one study per patient, but there can be multiple</em></li>
<li>Inside every study folder, there should be images (JPG format, ending in .jpg). <em>In our example, we have one image per study, but you might have a frontal and a lateral view.</em></li>
</ol>
<p>Finally, this ‘dataset’ folder should be zipped into a file called ‘dataset.zip’. We will use this zip file shortly.</p>
<p><br></p>
<h4 id="Image-Path-List"><a href="#Image-Path-List" class="headerlink" title="Image Path List"></a>Image Path List</h4><p>The second thing we’ll need is a file containing the paths of all images we’re running through the algorithm. This file will be in a CSV (spreadsheet) format, which can be generated by Microsoft Excel’s ‘save as’ function.</p>
<img src="/mlx/chexpert-validate/image_paths.png" alt="image_paths.csv file" title="image_paths.csv file"><span class="image-caption">image_paths.csv file</span>
<p>The CSV file should have the following structure:</p>
<ol>
<li>The file should contain only one column, with the top row as ‘Path’, and a list of image paths in subsequent rows.</li>
<li>The image paths must have the format dataset/{patient_name}/{study_name}/{image_name}.jpg </li>
</ol>
<p>This CSV should be saved with the name ‘image_paths.csv’.</p>
<p><br></p>
<h4 id="Ground-Truth"><a href="#Ground-Truth" class="headerlink" title="Ground Truth"></a>Ground Truth</h4><p>The third and final thing we’ll need is a file specifying the ground truth for each study. This file will also be in a CSV (spreadsheet) format.</p>
<img src="/mlx/chexpert-validate/ground_truths.png" alt="ground_truths.csv file" title="ground_truths.csv file"><span class="image-caption">ground_truths.csv file</span>
<p>This CSV file should have the following structure:</p>
<ol>
<li>Have 6 columns in total, with the first row containing ‘Study’, followed by the 5 pathologies the algorithm produces outputs for: Cardiomegaly, Edema, Consolidation, Atelectasis, and Pleural Effusion. <em>Our algorithm does not currently support more than these pathologies.</em></li>
<li>The paths (in the first column) should have the format ‘dataset/{patient_name}/{study_name}’. <em>Note that these are paths to the studies, not to the images, different from image_paths.csv, which specifies the filenames, while this file specifies the studies. Remember that a study can contain multiple images, but only has one ground truth.</em></li>
<li>The values for the ground truth should be 1 or 0, denoting the presence or absence of the pathology.</li>
</ol>
<p>This CSV file should be saved with the name ‘ground_truths.csv’.</p>
<p><br></p>
<h4 id="Recommendations-For-Setting-Up-Your-Data"><a href="#Recommendations-For-Setting-Up-Your-Data" class="headerlink" title="Recommendations For Setting Up Your Data"></a>Recommendations For Setting Up Your Data</h4><p><em>Ground Truth: Try to set as strong a ground truth as possible on your data. In our previous setups, we’ve used the majority vote of multiple radiologists as the ground truth; others use CT confirmations when possible. A strong ground truth sets the best possible assessment of the model on the data.</em><br><em>Sample size: Aim for as large a validation set as possible. We’ve used the heuristic that the prevalence for each of the pathologies be at least 30 studies.</em><br><em>Images:  We recommend that the input images be close to square, and grayscale (not color), and that images be smaller than 500x500, since the model will downsample them to 320x320 during training.</em></p>
<p><br></p>
<h3 id="Running-the-CheXpert-model-on-your-data"><a href="#Running-the-CheXpert-model-on-your-data" class="headerlink" title="Running the CheXpert model on your data"></a>Running the CheXpert model on your data</h3><p>We will now run through how you can run the CheXpert model we’ve pre-trained on Stanford data on the dataset you’ve prepared. <em>If you’re using our example data, now’s a good time to <a href="https://drive.google.com/drive/folders/1WVKMv9NWwxg69XZcTtjJgdl9IdKkEJ8T?usp=sharing">download it if you haven’t already</a>.</em> At the end of this section, you’ll be able to see the Area Under the Curve (AUC) metric of the model for the 5 tasks on your data (or the example data).</p>
<p><br><br><img src="/mlx/chexpert-validate/final.png" alt="The final output we'll work towards" title="The final output we'll work towards"><span class="image-caption">The final output we'll work towards</span><br><br></p>
<h4 id="Creating-An-Account-on-Codalab"><a href="#Creating-An-Account-on-Codalab" class="headerlink" title="Creating An Account on Codalab."></a>Creating An Account on Codalab.</h4><p>We’ll be using the Codalab platform for running the model on your data. CodaLab is an online platform for collaborative and reproducible computational research, developed by Percy Liang at Stanford. The platform has an interface for running commands, using which you will upload your data and run the Chexpert model.</p>
<p>First, we’ll create an account on Codalab:</p>
<ol>
<li>Go to <a href="http://worksheets.codalab.org">http://worksheets.codalab.org</a> and click “Sign Up” in the top-right corner.</li>
<li>Fill out the subsequent form.</li>
<li>A verification email will be sent to the email address you used to sign up. When you open it, there will be a link to follow in order to verify your account.</li>
<li>After verifying your account, sign in again.</li>
<li>Click on the My Dashboard Link at the top. </li>
</ol>
<p><br></p>
<h4 id="Uploading-the-data-on-Codalab"><a href="#Uploading-the-data-on-Codalab" class="headerlink" title="Uploading the data on Codalab"></a>Uploading the data on Codalab</h4><p>We will create a worksheet to organize and setup the running of the model on our data, beginning with uploading the data.</p>
<p>Now, click on ‘New Worksheet’ on the right sidebar.</p>
<p><br><br><img src="/mlx/chexpert-validate/new_worksheet.png" alt="New Worksheet" title="New Worksheet"><span class="image-caption">New Worksheet</span><br><br></p>
<p>It should prompt you to enter a name for the worksheet.<br><br><br><img src="/mlx/chexpert-validate/new_worksheet_2.png" alt="New Worksheet Name" title="New Worksheet Name"><span class="image-caption">New Worksheet Name</span><br><br></p>
<p>Click on the ‘Upload’ button in the sidebar:<br><br><br><img src="/mlx/chexpert-validate/upload.png" alt="Upload" title="Upload"><span class="image-caption">Upload</span><br><br></p>
<p>Upload dataset.zip first. In a few seconds, you should see a table with a row added on the left side of the page (refresh the page if you don’t). Then upload image_paths.csv, and then ground_truths.csv, one by one.<br><br><br><img src="/mlx/chexpert-validate/upload2.png" alt="All Files Are Uploaded" title="All Files Are Uploaded"><span class="image-caption">All Files Are Uploaded</span><br><br></p>
<h4 id="Running-the-CheXPert-Model-on-the-Uploaded-Data"><a href="#Running-the-CheXPert-Model-on-the-Uploaded-Data" class="headerlink" title="Running the CheXPert Model on the Uploaded Data"></a>Running the CheXPert Model on the Uploaded Data</h4><p>Now that the data is in place, we’re going to run the CheXPert model on it.</p>
<p>We’re going to first click on the gray pane at the top of the webpage (might contain ‘Codalab&gt;’).<br><br><br><img src="/mlx/chexpert-validate/command_line.png" alt="Click the Command Pane" title="Click the Command Pane"><span class="image-caption">Click the Command Pane</span><br><br></p>
<p>Once we have clicked on the commands pane, the pane will expand. Copy the following command into the pane, and press enter:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">macro chexpert-validate/validate dataset image_paths.csv ground_truths.csv</div></pre></td></tr></table></figure></p>
<p><br><br><img src="/mlx/chexpert-validate/command1.png" alt="Enter the Command" title="Enter the Command"><span class="image-caption">Enter the Command</span><br><br></p>
<p>In a second or two, you should see some output from the interface (after you’ve pressed enter).<br>Then click outside the pane (shown in figure below).</p>
<p>Congratulations, you’ve already kicked off the run of the model on the data in just one line. </p>
<p><em>There’s a lot of magic behind the scenes that Codalab performs to make this possible in just one line. Behind the scenes, the CheXpert model is being downloaded onto a remote machine with a GPU instance, on which a Docker container will be set up soon. This Docker container loads all the required dependencies to run the exact environment that the model needs.</em></p>
<p><br><br><img src="/mlx/chexpert-validate/command2.png" alt="See the outputs and click outside" title="See the outputs and click outside"><span class="image-caption">See the outputs and click outside</span><br><br></p>
<p>You should be able to see a few rows added to the table on the left of the page. </p>
<p><br><br><img src="/mlx/chexpert-validate/check1.png" alt="Verify that a few files are appended to your worksheet" title="Verify that a few files are appended to your worksheet"><span class="image-caption">Verify that a few files are appended to your worksheet</span><br><br></p>
<p>Click on the ‘new-run’ row of the table. The sidebar should change, and now display information about the status of the model’s run on the data. We’re going to give special attention to the ‘state’ of the run, which will start off with ‘preparing’ then move to ‘running’ and then ‘ready’. The ‘preparing’ state can take a few minutes, as the remote machine downloads the CheXpert models.</p>
<p><br><br><img src="/mlx/chexpert-validate/check2.png" alt="Check the status" title="Check the status"><span class="image-caption">Check the status</span><br><br></p>
<p>Soon, the status of the run should update to ‘running’. Now the model has been loaded on to a machine, and predictions are being made on the uploaded dataset. This takes 10 minutes for us using the example dataset, and will take longer on a larger dataset. <em>Note that the Chexpert model is not one model, but a collection of 30 specialist models, which must each be sequentially run on the data.</em></p>
<p><br><br><img src="/mlx/chexpert-validate/check3.png" alt="Check the status again" title="Check the status again"><span class="image-caption">Check the status again</span><br><br></p>
<p>Once the model has finished running, the status of the run will update to ‘ready’. In a few seconds, the table should auto-populate (refresh the page if it doesn’t) with the AUC scores of the model on the data across the various tasks (using the ground truth you’ve supplied).</p>
<p><em>If you see an error, please go back to the previous steps, and make sure that you haven’t missed any instructions.</em></p>
<p><em>Optional: if you’re an advanced user looking for confidence intervals on the AUC or further statistical analysis, advanced users can download the prediction file by clicking on the ‘new_predictions’ row, and then clicking download on the sidebar.</em></p>
<p><br><br><img src="/mlx/chexpert-validate/ready.png" alt="Running is completed" title="Running is completed"><span class="image-caption">Running is completed</span><br><br></p>
<p>And that’s it! In just over an hour, we’ve been able to run the CheXpert model on your own data (or the example data)!</p>
<p><br></p>
<h1 id="Join-us-in-a-worldwide-effort"><a href="#Join-us-in-a-worldwide-effort" class="headerlink" title="Join us in a worldwide effort"></a>Join us in a worldwide effort</h1><p>If you’ve followed our tutorial and successfully validated CheXpert model on your own institution’s data (or data that’s not from our google image example), we’d love to know! Please let us know how CheXpert did on your population! We encourage you to publish, and to also join our efforts in compiling the performances of the model on data worldwide. Email us at:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pranavsr@stanford.edu, jirvin16@stanford.edu, mlungren@stanford.edu </div></pre></td></tr></table></figure></p>
<p><br></p>
<h4 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h4><p>Thanks to our colleagues Nguyet Minh Phu and Mark Sabini for collecting and labeling the google images dataset we use in our example.</p>

                
                    
    <hr />
    <h3>Comments:</h3>
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>



                
            </div>
            <div class="col-md-3">
                <h2> Also Read </h2>
                <hr>
                
                    <div class="post-preview">
    <a href="/mlx/treatment-effects/">
        <h1 class="post-title archive">
            Treatment Effects with Decision Trees
        </h1>
    </a>
    <p class="post-meta archive">
        <!-- Date and Author -->
        
            By Pranav Rajpurkar on
        
        September 6th 2017
    </p>
</div>
                
                    <div class="post-preview">
    <a href="/mlx/visualizing-cnns/">
        <h1 class="post-title archive">
            Visualizing A Convolutional Neural Network's Predictions
        </h1>
    </a>
    <p class="post-meta archive">
        <!-- Date and Author -->
        
            By Pranav Rajpurkar on
        
        September 18th 2017
    </p>
</div>
                
                    <div class="post-preview">
    <a href="/mlx/risk-stratification/">
        <h1 class="post-title archive">
            Risk Stratification For Patient Care
        </h1>
    </a>
    <p class="post-meta archive">
        <!-- Date and Author -->
        
            By Pranav Rajpurkar on
        
        September 2nd 2017
    </p>
</div>
                
                <hr>
                
                    


<a href="/mlx/tags/AI/">#AI</a> <a href="/mlx/tags/medicine/">#medicine</a> <a href="/mlx/tags/external-validation/">#external validation</a>


                
            </div>
        </div>
    </div>
</article>



    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                        <li>
                            <a href="https://twitter.com/pranavrajpurkar" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    
                        <li>
                            <a href="https://github.com/rajpurkar/mlx" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    
                        <li>
                            <a href="mailto:pranavsr@cs.stanford.edu" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-envelope-o fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="/mlx/bower_components/jquery/dist/jquery.min.js"></script>

<!-- Bootstrap -->
<script src="/mlx/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>

<!-- Disqus Comments -->

<script type="text/javascript">
    var disqus_shortname = 'mlx-2';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>


<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script src="/mlx/bower_components/MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>


</body>

</html>